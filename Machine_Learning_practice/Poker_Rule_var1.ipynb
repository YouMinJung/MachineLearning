{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poker Rule\n",
    "\n",
    "\n",
    "* sampleSubmission.csv *\n",
    "\n",
    ">  Submission file should predict the hand for each id in the test set.\n",
    "\n",
    "id,hand\n",
    "1,0\n",
    "2,0\n",
    "3,9\n",
    "...\n",
    "etc.\n",
    "\n",
    "\n",
    "* train.csv, test.csv *\n",
    "\n",
    ">  Each hand consists of five cards with a given suit and rank, drawn from a standard deck of 52.\n",
    "\n",
    "<p>S1 “Suit of card #1”</p>\n",
    "<p>Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs} </p>\n",
    "<p>C1 “Rank of card #1”</p>\n",
    "<p>Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King) </p>\n",
    "...\n",
    "\n",
    "<p>S5 “Suit of card #5”</p>\n",
    "<p>C5 “Rank of card #5”</p>\n",
    "\n",
    "\n",
    ">  Each row in the training set has the accompanying class label for the poker hand it comprises.\n",
    "\n",
    "<p>0: Nothing in hand; not a recognized poker hand</p>\n",
    "<p>1: One pair; one pair of equal ranks within five cards</p>\n",
    "<p>2: Two pairs; two pairs of equal ranks within five cards</p>\n",
    "<p>3: Three of a kind; three equal ranks within five cards</p>\n",
    "<p>4: Straight; five cards, sequentially ranked with no gaps</p>\n",
    "<p>5: Flush; five cards with the same suit</p>\n",
    "<p>6: Full house; pair + different rank three of a kind</p>\n",
    "<p>7: Four of a kind; four equal ranks within five cards</p>\n",
    "<p>8: Straight flush; straight + flush</p>\n",
    "<p>9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection as modsel\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25010, 11)\n"
     ]
    }
   ],
   "source": [
    "# train data\n",
    "\n",
    "train_data = pd.read_csv(\"./data/Poker_Rule/train.csv\")\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S1  C1  S2  C2  S3  C3  S4  C4  S5  C5  hand\n",
      "0       4   9   2   1   2   2   4   7   2   8     0\n",
      "1       1   4   3   6   1  12   3  11   2   7     0\n",
      "2       1  11   4   1   3   7   4  11   2   1     2\n",
      "3       2   9   2   4   3   6   1   9   4   9     3\n",
      "4       1   8   2   4   2  11   2   2   2   1     0\n",
      "5       2   5   1   5   2  13   2   3   3  13     2\n",
      "6       3  10   4   6   1   4   2  13   4   5     0\n",
      "7       4  10   3   1   2  13   4   2   4   7     0\n",
      "8       3   2   4  10   3   3   4   4   1   9     0\n",
      "9       2   7   3   8   4   8   2  13   2  12     1\n",
      "10      2   5   1   3   2  10   3   2   2   1     0\n",
      "11      1   6   2  12   4   7   2  10   1   1     0\n",
      "12      4   2   4   9   1  12   3   7   2  11     0\n",
      "13      2   6   1   5   3   3   4   2   4   5     1\n",
      "14      1   6   3  12   4  11   2  11   3  13     1\n",
      "15      2   5   2   4   4   9   2   3   3   2     0\n",
      "16      4   9   4  11   3   8   3   9   3   5     1\n",
      "17      1   9   2   4   1  11   3   4   1  13     1\n",
      "18      1  11   3  13   4   8   4   1   3   6     0\n",
      "19      2   6   1  12   3   8   4   1   4   6     1\n",
      "20      2   9   3   7   1  13   2  13   1   2     1\n",
      "21      4   4   2  13   3   6   2   7   3   3     0\n",
      "22      3   6   1   4   3   1   2   5   4   9     0\n",
      "23      1   4   4   3   2  11   4  13   1  10     0\n",
      "24      3   9   2   7   2   4   2   1   1  10     0\n",
      "25      2   4   4   2   1   4   4   1   3  11     1\n",
      "26      2   8   1   4   3  11   1   8   1   2     1\n",
      "27      3   8   1  12   4   1   4  10   1   3     0\n",
      "28      2  12   1   5   1   2   1  10   2   8     0\n",
      "29      2   4   4   7   4   2   4  11   2   2     1\n",
      "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   ...\n",
      "24980   2   5   4  13   1   3   4   8   3   9     0\n",
      "24981   3   7   4  11   3   1   1  13   4   3     0\n",
      "24982   4  10   2   3   1   8   3  11   2   7     0\n",
      "24983   1   5   2   6   3  10   4  10   3   3     1\n",
      "24984   4  10   2   5   4   6   2  10   3  12     1\n",
      "24985   2   6   2   7   4   2   3   6   3   9     1\n",
      "24986   1   7   2   4   2   1   1   1   2  11     1\n",
      "24987   3   8   4  10   3   2   4   6   1  11     0\n",
      "24988   2   8   4   8   1   3   3   8   1   5     3\n",
      "24989   1   1   1   7   3   9   4   9   1   5     1\n",
      "24990   4   2   3   7   1  13   2  12   2   9     0\n",
      "24991   1   7   3  10   3  13   1  13   4  10     2\n",
      "24992   1  10   4   5   1   6   3   7   2   5     1\n",
      "24993   3   4   3   3   4  10   2   1   4   6     0\n",
      "24994   4   1   3   2   2  11   2   6   2   3     0\n",
      "24995   3   3   4   5   3   4   4   4   1   3     2\n",
      "24996   3   7   1  13   1   2   1   9   2  11     0\n",
      "24997   2  13   1   5   4   5   4   8   3   3     1\n",
      "24998   3   2   4  10   2   6   1  12   3  10     1\n",
      "24999   1   8   4   2   3   1   1   5   1  10     0\n",
      "25000   4   4   1  10   3  11   2   2   3   8     0\n",
      "25001   2  12   4   9   4  10   3  13   3   9     1\n",
      "25002   1  12   2  13   4   2   1   8   2  10     0\n",
      "25003   2   3   1   9   1   1   3   8   3   7     0\n",
      "25004   3   4   2   8   4   8   1   9   2  11     1\n",
      "25005   4   9   4   6   3   6   4  12   4   5     1\n",
      "25006   3   8   3   5   4  11   2   2   1  13     0\n",
      "25007   1   8   4   5   3  11   3   2   2  13     0\n",
      "25008   4  12   3   5   2   1   2   7   4   6     0\n",
      "25009   1   1   1   3   1   7   1   2   4   2     1\n",
      "\n",
      "[25010 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* S1, C1, ..., S5, C5는 feature.\n",
    "* hand는 label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = train_data['hand']\n",
    "features = train_data.drop(['hand'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=100, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=100, weights='uniform', algorithm='auto')\n",
    "\n",
    "# laerning knn\n",
    "knn.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 11)\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "\n",
    "test_data = pd.read_csv(\"./data/Poker_Rule/test.csv\")\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id  S1  C1  S2  C2  S3  C3  S4  C4  S5  C5\n",
      "0             1   1  10   2   2   3   3   3   8   1   1\n",
      "1             2   2  13   3   5   3   7   4   6   1   4\n",
      "2             3   1   3   1  11   2   8   2   1   2   4\n",
      "3             4   1   6   3   3   4   7   1   8   3  11\n",
      "4             5   2  10   3   4   1   6   2  12   2   6\n",
      "5             6   1   4   3  10   2  11   2   6   1   7\n",
      "6             7   1  10   3   8   1   4   3  11   3   9\n",
      "7             8   2  11   3   8   1   1   1  11   2   3\n",
      "8             9   3   4   1   1   1   3   3   5   3   6\n",
      "9            10   3  12   2   1   1   3   1   2   3  10\n",
      "10           11   1   7   3   1   4   8   4  10   3  11\n",
      "11           12   2   3   2  11   3   9   1  10   2   5\n",
      "12           13   1   4   2  13   4   6   4   8   4   5\n",
      "13           14   4   7   4   2   3   3   1   4   1   1\n",
      "14           15   4   8   3  10   4  11   3   5   1  12\n",
      "15           16   4  11   1  10   1   3   1   2   4   5\n",
      "16           17   1   8   3   2   4   4   2   3   3   4\n",
      "17           18   3   7   1   6   1   4   3  12   3   6\n",
      "18           19   2   4   1   1   1   9   3   1   2  13\n",
      "19           20   2   8   1  13   3   2   4   1   4   9\n",
      "20           21   2   3   1  10   4  12   3  10   2   8\n",
      "21           22   1   2   3   6   4   7   1   6   3   8\n",
      "22           23   1   6   1   3   2   2   1   9   4   5\n",
      "23           24   2   1   4   8   3  11   3   1   2  13\n",
      "24           25   4   3   4   8   1   9   1   7   4   4\n",
      "25           26   2  13   4   4   1  12   2   5   3  12\n",
      "26           27   1   4   4   4   1   5   3   5   2   2\n",
      "27           28   2  13   3  13   1   2   1   9   1   1\n",
      "28           29   1   2   3  10   4   8   3   9   2  10\n",
      "29           30   1   7   1   3   3   8   1   1   2   5\n",
      "...         ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
      "999970   999971   2   7   1   7   3   8   2  11   4  10\n",
      "999971   999972   1  13   4   2   2  12   3   8   4   5\n",
      "999972   999973   4   8   1   6   3  12   3   5   4  11\n",
      "999973   999974   1  11   3   6   4   9   3  11   1   8\n",
      "999974   999975   3  11   3  10   4  12   4   8   4   9\n",
      "999975   999976   1  11   3   1   1  10   4  10   2   6\n",
      "999976   999977   1   2   1  13   3  11   2  11   3   8\n",
      "999977   999978   4   8   4  11   1   9   2   7   3   8\n",
      "999978   999979   3  12   3   2   1  12   2   9   2   5\n",
      "999979   999980   3   9   3   2   4  11   3   7   4  10\n",
      "999980   999981   4   3   2  11   1   1   4   2   2  13\n",
      "999981   999982   2  13   2   2   4  10   4  12   4   7\n",
      "999982   999983   4   6   1  11   3   7   4   9   1   4\n",
      "999983   999984   4   6   4   8   1   9   3   5   1   4\n",
      "999984   999985   2  13   1   9   3   1   1   4   3  10\n",
      "999985   999986   3   8   1   3   1  11   1   5   1  12\n",
      "999986   999987   2   6   4   3   1   1   4   7   4   9\n",
      "999987   999988   3   2   4   6   4   2   3  13   2  13\n",
      "999988   999989   1   1   1   5   3   4   2   1   4   9\n",
      "999989   999990   1   8   2   9   1   2   3   8   3  11\n",
      "999990   999991   1   5   2  13   4  10   4   2   4  12\n",
      "999991   999992   4   4   4   1   3   1   2   1   3  12\n",
      "999992   999993   2  11   1  13   4  13   3   1   4   1\n",
      "999993   999994   2   7   3   5   3   3   1   6   1   3\n",
      "999994   999995   2   7   4  13   4   5   2   2   1   5\n",
      "999995   999996   2   8   3   4   1  13   3   8   2   5\n",
      "999996   999997   2   8   2   7   4  11   4   8   3   6\n",
      "999997   999998   1   7   1   8   1   5   2   9   2   5\n",
      "999998   999999   1   1   2   7   2  13   2   5   3  10\n",
      "999999  1000000   2   2   3   3   1   3   4   4   3  11\n",
      "\n",
      "[1000000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train data의 ['hand']부분을 예측해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make test dataframe only exist features to predict\n",
    "test_data = test_data.drop(['id'], axis=1)\n",
    "\n",
    "# predict\n",
    "predict = knn.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ..., 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* predict는 예상된 'hand' 값."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.591923230708\n"
     ]
    }
   ],
   "source": [
    "# training set accuracy score\n",
    "\n",
    "print(knn.score(features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# testing set accuracy score\n",
    "\n",
    "print(knn.score(test_data, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>=> 1.0은 너무 학습이 잘된 것 같다... (과적합?)</p>\n",
    "<p>=> 정화도 계산 방법이 잘 못 된 것 같다...</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train_data = pd.read_csv(\"./data/Poker_Rule/train.csv\")\n",
    "test_data = pd.read_csv(\"./data/Poker_Rule/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(kernel='linear')           # create SVM - linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_data = train_data[[\"S1\",\"C1\",\"S2\",\"C2\",\"S3\",\"C3\",\"S4\",\"C4\",\"S5\",\"C5\"]]\n",
    "csv_label = train_data[\"hand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trining\n",
    "svm_model.fit(csv_data, csv_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set test data\n",
    "test_csv_data = test_data[[\"S1\",\"C1\",\"S2\",\"C2\",\"S3\",\"C3\",\"S4\",\"C4\",\"S5\",\"C5\"]]\n",
    "\n",
    "# predict\n",
    "predict = svm_model.predict(test_csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** train data에서 train과 test를 0.3비율로 나누어 수행 -> accuracy 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_data, Test_data, Train_label, Test_label = train_test_split(csv_data, csv_label, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494868719179\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(Train_data, Train_label)\n",
    "pre = svm_model.predict(Test_data)\n",
    "accuracy_score = metrics.accuracy_score(Test_label, pre)\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> 정말 낮은 정확도가 나왔다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494868719179\n"
     ]
    }
   ],
   "source": [
    "svm_model_g = svm.SVC(kernel='rbf', C=10.0, gamma=0.10, random_state=0)   # Gaussian\n",
    "\n",
    "svm_model_g.fit(Train_data, Train_label)\n",
    "pre_g = svm_model.predict(Test_data)\n",
    "accuracy_score_g = metrics.accuracy_score(Test_label, pre_g)\n",
    "print(accuracy_score_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> ?????  비선형으로 바꾸어도...;;; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Division data 7:3\n",
    "test_index = [x for x in df_train.index if x % 3 == 0]\n",
    "train_index = [x for x in df_train.index if x % 3 != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25010 entries, 0 to 25009\n",
      "Data columns (total 11 columns):\n",
      "S1      25010 non-null int64\n",
      "C1      25010 non-null int64\n",
      "S2      25010 non-null int64\n",
      "C2      25010 non-null int64\n",
      "S3      25010 non-null int64\n",
      "C3      25010 non-null int64\n",
      "S4      25010 non-null int64\n",
      "C4      25010 non-null int64\n",
      "S5      25010 non-null int64\n",
      "C5      25010 non-null int64\n",
      "hand    25010 non-null int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy :  convert data to category\n",
    "df_train1 = pd.concat([pd.get_dummies(df_train.S1),\n",
    "pd.get_dummies(df_train.S2),\n",
    "pd.get_dummies(df_train.S3),\n",
    "pd.get_dummies(df_train.S4),\n",
    "pd.get_dummies(df_train.S5)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if S1~S4 data sxist, data = 1\n",
    "# else data = 0\n",
    "\n",
    "df_train = pd.concat([df_train,df_train1],axis=1)\n",
    "df_train = df_train.drop(['S1','S2','S3','S4','S5'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25010 entries, 0 to 25009\n",
      "Data columns (total 26 columns):\n",
      "C1      25010 non-null int64\n",
      "C2      25010 non-null int64\n",
      "C3      25010 non-null int64\n",
      "C4      25010 non-null int64\n",
      "C5      25010 non-null int64\n",
      "hand    25010 non-null int64\n",
      "1       25010 non-null uint8\n",
      "2       25010 non-null uint8\n",
      "3       25010 non-null uint8\n",
      "4       25010 non-null uint8\n",
      "1       25010 non-null uint8\n",
      "2       25010 non-null uint8\n",
      "3       25010 non-null uint8\n",
      "4       25010 non-null uint8\n",
      "1       25010 non-null uint8\n",
      "2       25010 non-null uint8\n",
      "3       25010 non-null uint8\n",
      "4       25010 non-null uint8\n",
      "1       25010 non-null uint8\n",
      "2       25010 non-null uint8\n",
      "3       25010 non-null uint8\n",
      "4       25010 non-null uint8\n",
      "1       25010 non-null uint8\n",
      "2       25010 non-null uint8\n",
      "3       25010 non-null uint8\n",
      "4       25010 non-null uint8\n",
      "dtypes: int64(6), uint8(20)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test data set\n",
    "df_test1 = pd.concat([pd.get_dummies(df_test.S1),\n",
    "pd.get_dummies(df_test.S2),\n",
    "pd.get_dummies(df_test.S3),\n",
    "pd.get_dummies(df_test.S4),\n",
    "pd.get_dummies(df_test.S5)],axis=1)\n",
    "\n",
    "df_test = pd.concat([df_test,df_test1],axis=1)\n",
    "df_test = df_test.drop(['S1','S2','S3','S4','S5'],axis=1)\n",
    "\n",
    "# drop label data\n",
    "xtrain = df_train.drop('hand',axis=1)\n",
    "\n",
    "# compare data\n",
    "ytrain = df_train['hand']\n",
    "xtest = df_test.drop('id',axis=1)\n",
    "id = df_test['id']  # make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn modeling \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5) # k = 5, group\n",
    "model.fit(xtrain,ytrain)\n",
    "y_pred = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# result -> using Kaggle\n",
    "submission = pd.DataFrame({'id':id, 'hand':y_pred})\n",
    "submission = submission[['id','hand']]\n",
    "submission.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Accuracy Score : 53.57%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character + Number\n",
    "\n",
    "# train\n",
    "df_train['SC1'] = df_train['S1'].apply(lambda x: str(x)) + df_train['C1'].apply(lambda x: str(x))\n",
    "df_train['SC2'] = df_train['S2'].apply(lambda x: str(x)) + df_train['C2'].apply(lambda x: str(x))\n",
    "df_train['SC3'] = df_train['S3'].apply(lambda x: str(x)) + df_train['C3'].apply(lambda x: str(x))\n",
    "df_train['SC4'] = df_train['S4'].apply(lambda x: str(x)) + df_train['C4'].apply(lambda x: str(x))\n",
    "df_train['SC5'] = df_train['S5'].apply(lambda x: str(x)) + df_train['C5'].apply(lambda x: str(x))\n",
    "xtrain = pd.get_dummies(df_train['SC1']) + pd.get_dummies(df_train['SC2']) +pd.get_dummies(df_train['SC3']) + pd.get_dummies(df_train['SC4']) + pd.get_dummies(df_train['SC5'])\n",
    "\n",
    "# test\n",
    "df_test['SC1'] = df_test['S1'].apply(lambda x: str(x)) + df_test['C1'].apply(lambda x: str(x))\n",
    "df_test['SC2'] = df_test['S2'].apply(lambda x: str(x)) + df_test['C2'].apply(lambda x: str(x))\n",
    "df_test['SC3'] = df_test['S3'].apply(lambda x: str(x)) + df_test['C3'].apply(lambda x: str(x))\n",
    "df_test['SC4'] = df_test['S4'].apply(lambda x: str(x)) + df_test['C4'].apply(lambda x: str(x))\n",
    "df_test['SC5'] = df_test['S5'].apply(lambda x: str(x)) + df_test['C5'].apply(lambda x: str(x))\n",
    "xtest = pd.get_dummies(df_test['SC1']) + pd.get_dummies(df_test['SC2']) +pd.get_dummies(df_test['SC3']) + pd.get_dummies(df_test['SC4']) + pd.get_dummies(df_test['SC5'])\n",
    "\n",
    "df_train = df_train.drop(['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5'],axis=1)\n",
    "df_test = df_test.drop(['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5'],axis=1)\n",
    "\n",
    "xtrain = df_train.drop('hand',axis=1)\n",
    "ytrain = df_train['hand']\n",
    "id = df_test['id']\n",
    "xtest = df_test.drop('id',axis=1)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(xtrain,ytrain)\n",
    "y_pred = model.predict(xtest)\n",
    "\n",
    "submission = pd.DataFrame({'id':id, 'hand':y_pred})\n",
    "submission = submission[['id','hand']]\n",
    "submission.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> 성능이 더 떨어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train = df_train.drop(['S1','S2','S3','S4','S5'],axis=1)\n",
    "df_test = df_test.drop(['S1','S2','S3','S4','S5'],axis=1)\n",
    "\n",
    "# only use number data\n",
    "df_train1 = pd.get_dummies(df_train.C1) + pd.get_dummies(df_train.C2) + pd.get_dummies(df_train.C3) + pd.get_dummies(df_train.C4) + pd.get_dummies(df_train.C5)\n",
    "df_test1 = pd.get_dummies(df_test.C1) + pd.get_dummies(df_test.C2) + pd.get_dummies(df_test.C3) + pd.get_dummies(df_test.C4) + pd.get_dummies(df_test.C5)\n",
    "\n",
    "xtrain = df_train1\n",
    "ytrain = df_train['hand']\n",
    "id = df_test['id']\n",
    "xtest = df_test1\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(xtrain,ytrain)\n",
    "y_pred = model.predict(xtest)\n",
    "\n",
    "submission = pd.DataFrame({'id':id, 'hand':y_pred})\n",
    "submission = submission[['id','hand']]\n",
    "submission.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> 성능 상승 (98.3%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randon Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "df_train = df_train = df_train.drop(['S1','S2','S3','S4','S5'],axis=1)\n",
    "df_test = df_test.drop(['S1','S2','S3','S4','S5'],axis=1)\n",
    "\n",
    "df_train1 = pd.get_dummies(df_train.C1) + pd.get_dummies(df_train.C2) + pd.get_dummies(df_train.C3) + pd.get_dummies(df_train.C4) + pd.get_dummies(df_train.C5)\n",
    "df_test1 = pd.get_dummies(df_test.C1) + pd.get_dummies(df_test.C2) + pd.get_dummies(df_test.C3) + pd.get_dummies(df_test.C4) + pd.get_dummies(df_test.C5)\n",
    "\n",
    "xtrain = df_train.drop('hand',axis=1)\n",
    "ytrain = df_train['hand']\n",
    "id = df_test['id']\n",
    "xtest = df_test.drop('id',axis=1)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10)\n",
    "model.fit(xtrain,ytrain)\n",
    "y_pred = model.predict(xtest)\n",
    "\n",
    "submission = pd.DataFrame({'id':id, 'hand':y_pred})\n",
    "submission = submission[['id','hand']]\n",
    "submission.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> KNN보다 성능이 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ensenble & Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensenble: 성능(정확도)이 낮은 모델들을 여러 개 모아서 실질적으로 성능을 향상시키는 기법\n",
    "- Stacking: 앙상블하는 과정 중 하나로 다양한 학습 알고리즘을 통해 구성된 모델을 조합하는 방식으로 각 분류기의 성능을 추정하는 방식\n",
    "<br><br>\n",
    "- 다음의 모델들을 앙상블 및 스태킹하여 모델을 제작\n",
    "  - GradientBoostingClassifier()\n",
    "  - RandomForestClassifier()\n",
    "  - ExtraTreeClassifier()\n",
    "  - KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "test_index = [x for x in df_train.index if x % 3 == 0] #30% testset\n",
    "train_index = [x for x in df_train.index if x % 3 != 0] #70% trainingset\n",
    "\n",
    "df_train = df_train = df_train.drop(['S1','S2','S3','S4','S5'],axis=1)\n",
    "df_test = df_test.drop(['S1','S2','S3','S4','S5'],axis=1)\n",
    "\n",
    "df_train1 = pd.get_dummies(df_train.C1) + pd.get_dummies(df_train.C2) + pd.get_dummies(df_train.C3) + pd.get_dummies(df_train.C4) + pd.get_dummies(df_train.C5)\n",
    "df_test1 = pd.get_dummies(df_test.C1) + pd.get_dummies(df_test.C2) + pd.get_dummies(df_test.C3) + pd.get_dummies(df_test.C4) + pd.get_dummies(df_test.C5)\n",
    "\n",
    "xtrain = df_train1\n",
    "ytrain = df_train['hand']\n",
    "id = df_test['id']\n",
    "xtest = df_test1\n",
    "\n",
    "\n",
    "# 교차검증(Cross Validation) : 5개의 그룹으로 분류해 K-Fold 방식으로 교차검증을 진행\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "regs = [GradientBoostingClassifier(n_estimators=10),\n",
    "        GradientBoostingClassifier(n_estimators=50),\n",
    "        RandomForestClassifier(n_estimators=10),\n",
    "        RandomForestClassifier(n_estimators=50),\n",
    "        ExtraTreesClassifier(n_estimators=10),\n",
    "        ExtraTreesClassifier(n_estimators=50),\n",
    "        KNeighborsClassifier(n_neighbors=1),\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        LassoCV(cv=10,n_alphas=1000),\n",
    "        LassoCV(cv=5, n_alphas=1000)]\n",
    "\n",
    "meta_feature = pd.DataFrame(np.zeros(xtrain.shape[0]))\n",
    "for train_index, test_index in cv.split(xtrain):\n",
    "    xtrain_train = xtrain.ix[train_index]\n",
    "    xtrain_test = xtrain.ix[test_index]\n",
    "    ytrain_train = ytrain.ix[train_index]\n",
    "    ytrain_test = ytrain.ix[test_index]\n",
    "    reg_num = 0\n",
    "    for reg in regs:\n",
    "        reg_name = str(reg_num) + str(reg.__class__).split('.')[-1].split(\"'\")[0]\n",
    "        reg.fit(xtrain_train, ytrain_train)\n",
    "        meta_feature.ix[test_index, reg_name] = reg.predict(xtrain_test)\n",
    "        reg_num += 1\n",
    "meta_feature = meta_feature.drop(0,axis=1)\n",
    "\n",
    "meta_feature_test = pd.DataFrame(np.zeros(xtest.shape[0]))\n",
    "reg_num = 0\n",
    "for reg in regs:\n",
    "    reg_name = str(reg_num) + str(reg.__class__).split('.')[-1].split(\"'\")[0]\n",
    "    reg.fit(xtrain, ytrain)\n",
    "    meta_feature_test[reg_name] = reg.predict(xtest)\n",
    "    reg_num += 1\n",
    "meta_feature_test = meta_feature_test.drop(0, axis=1)\n",
    "\n",
    "stacker = GradientBoostingClassifier(n_estimators=10)\n",
    "stacker.fit(meta_feature,ytrain)\n",
    "y_pred = stacker.predict(meta_feature_test)\n",
    "\n",
    "submission = pd.DataFrame({'id':id, 'hand':y_pred})\n",
    "submission = submission[['id','hand']]\n",
    "submission.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>=> Number만 사용하는 경우가 성능이 더 좋음</p>\n",
    "<p>=> RandomForestClassifier 모델과 GradientBoostingClassifier 모델, ExtraTreesClassifier 모델을 함께 Stacking ensemble 하여 사용하는 것이 가장 좋음</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
